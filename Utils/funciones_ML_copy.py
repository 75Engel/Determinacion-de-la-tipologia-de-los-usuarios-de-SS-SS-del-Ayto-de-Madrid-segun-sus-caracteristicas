{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficas(df,y):\n",
    "    '''\n",
    "    Función para representar varias graficas antes de realizar cualquier modelo\n",
    "    df es un DataFrame\n",
    "    y es la variable dependiente y se expresa como df(['y])\n",
    "    '''\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.pairplot(df)\n",
    "    fig, axes = plt.subplots(2,1)\n",
    "    sns.distplot(y, ax = axes[0])\n",
    "    sns.heatmap(df.corr(), annot=True, ax = axes[1])\n",
    "    axes[0].set_title(\"Distribucion\")\n",
    "    axes[1].set_title(\"Mapa Correlación\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "                         #   Defines el modelo como lineal regression\n",
    "                                                        #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "#X_train, X_test, y_train, y_test = train_test_split (X,y)\n",
    "#baseline_error = metrics.mean_squared_error(y_test, lin_reg.predict(X_test))            #   Esta linea no está clara todavia, me da error \n",
    "'''Hay una serie de variables fuera de la función que hay que declarar antes, estas son las de arriba'''\n",
    "\n",
    "def funcion_lineal_regression(X,y,test_size_1,random_state_1):\n",
    "    '''Función para ingresar el dataframe, las variables predictorias (X), \n",
    "    la variable a determinar, el factor size y el random'''\n",
    "    lin_reg = LinearRegression()   \n",
    "    lin_reg.fit(X_train, y_train)                           #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=random_state_1)\n",
    "\n",
    "    print(\"Estos son los datos del test y del target:\\n-----\")\n",
    "    print(\"Total features shape:\", X.shape)\n",
    "    print(\"Train features shape:\", X_train.shape)\n",
    "    print(\"Train target shape:\", y_train.shape)\n",
    "    print(\"Test features shape:\", X_test.shape)\n",
    "    print(\"Test target shape:\", y_test.shape)  \n",
    "\n",
    "#    print(\"Estos son los datos del valor de y en x=0 y de las pendientes de cada gradiente de las variables:\\n-----\")\n",
    "#    print(lin_reg.intercept_)\n",
    "#    print(lin_reg.coef_)\n",
    "    coeff_df = pd.DataFrame(lin_reg.coef_,\n",
    "                            X.columns,\n",
    "                            columns=['Coefficient'])\n",
    "    print(\"Estos son las pendientes de cada gradiente visto en un Dataframe:\\n-----\")\n",
    "    print(coeff_df)\n",
    "\n",
    "    predictions = lin_reg.predict(X_test)                   #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "    print(\"El factor de correlacion de la regresión es: \",lin_reg.score(X_test, y_test))\n",
    "    print(\"Errores de las predicciones:\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    print(\"\\nErrores de los tests\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MSE:', metrics.mean_squared_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, lin_reg.predict(X_train))))\n",
    "\n",
    "    print(\"Esta es la importancia de las variables:\\n-----\")\n",
    "    features = pd.DataFrame(lin_reg.coef_, X_train.columns, columns=['coefficient'])\n",
    "    print(features.head().sort_values('coefficient', ascending=False))\n",
    "\n",
    "\n",
    "#    baseline_error = metrics.mean_squared_error(y_test, lin_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def funcion_polynomial_regression(dataFrame,X_1,y_1,n_1,test_size_1,random_state_1):\n",
    "    '''Función para ingresar el dataframe, las variables predictorias (X), \n",
    "    la variable a determinar, el grado del polinomio, el factor size y el random'''\n",
    "    \n",
    "    print(\"Esta es la matriz de correlación de las variables:\")\n",
    "    sns.heatmap(dataFrame.corr(), annot=True);\n",
    "\n",
    "\n",
    "    poly_reg = PolynomialFeatures(degree=n_1)\n",
    "    poly_reg.fit(X_1)\n",
    "    X_poly = poly_reg.transform(X_1)\n",
    "    X_poly\n",
    "    y=y_1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=test_size_1, random_state=random_state_1)\n",
    "\n",
    "    print(\"Estos son los datos del test y del target:\\n-----\")\n",
    "    print(\"Total features shape:\", X_poly.shape)\n",
    "    print(\"Train features shape:\", X_train.shape)\n",
    "    print(\"Train target shape:\", y_train.shape)\n",
    "    print(\"Test features shape:\", X_test.shape)\n",
    "    print(\"Test target shape:\", y_test.shape) \n",
    "\n",
    "    poly_reg.fit(X_train)\n",
    "    X_poly_train = poly_reg.transform(X_train) \n",
    "\n",
    "    poly_reg_2 = LinearRegression()\n",
    "    poly_reg_2.fit(X_poly_train, y_train)\n",
    "\n",
    "    print(\"Estos son los datos del valor de y en x=0 y de las pendientes de cada gradiente de las variables:\\n-----\")\n",
    "    print(poly_reg_2.intercept_)\n",
    "    print(poly_reg_2.coef_)\n",
    "\n",
    "    predictions = poly_reg.predict(poly_reg.transform(X_test))  #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "    print(\"Estos son los resultados que predice el modelo:\\n-----\")\n",
    "    predictions                                             #   testear el modelo\n",
    "\n",
    "#    print(\"Esta es la gráfica donde represento los valores reales con los obtenidos por el modelo:\\n-----\")\n",
    "#    sns.scatterplot(y_test, predictions);\n",
    "\n",
    "    print(\"El factor de la regresión lineal es: \",poly_reg.score(poly_reg.transform(X_1),y))\n",
    "    print(\"Errores de las predicciones\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    print(\"\\nErrores de los tests\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_train, poly_reg_2.predict(X_train)))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_train, poly_reg_2.predict(X_train)))\n",
    "    print('MSE:', metrics.mean_squared_error(y_train, poly_reg_2.predict(X_train)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, poly_reg_2.predict(X_train))))\n",
    "\n",
    "#    print(\"Esta es la importancia de las variables:\\n-----\")\n",
    "#    features = pd.DataFrame(poly_reg.coef_, X_train.columns, columns=['coefficient'])\n",
    "#    features.head().sort_values('coefficient', ascending=False)\n",
    "\n",
    "#    std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "#    X_train_scal = std_scale.transform(X_train)\n",
    "\n",
    "#    poly_reg_scal = LinearRegression()\n",
    "#    poly_reg_scal.fit(X_train_scal, y_train)\n",
    "\n",
    "#    print(\"Esta es la importancia de las variables escaladas:\\n-----\")\n",
    "#    intercept_scal = poly_reg_scal.intercept_\n",
    "#    features_std = pd.DataFrame(poly_reg_scal.coef_, X_train.columns, columns=['coefficient'])\n",
    "#    features_std.sort_values('coefficient', ascending=False)\n",
    "#    features_std = features_std.sort_values('coefficient', ascending=True)\n",
    "#    plt.barh(features_std.index, features_std.coefficient);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_ridge (X,y,test_size_1,random_state_1,alpha_1):\n",
    "    lin_reg = LinearRegression() \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=random_state_1)\n",
    "    lin_reg.fit(X_train, y_train)                           #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "    predictions = lin_reg.predict(X_test)                   #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "    print(\"El factor de correlacion de la regresión es: \",lin_reg.score(X_test, y_test))\n",
    "    print(\"Errores de las predicciones:\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    print(\"\\nErrores de los tests\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MSE:', metrics.mean_squared_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, lin_reg.predict(X_train))))\n",
    "\n",
    "    ridgeR = Ridge(alpha = alpha_1)\n",
    "    ridgeR.fit(X_train, y_train)\n",
    "    print(\"------\")\n",
    "    print(\"Train MSE sin regularización:\", round(metrics.mean_squared_error(y_train, lin_reg.predict(X_train)),2))\n",
    "    print(\"Test MSE sin regularización:\", round(metrics.mean_squared_error(y_test, lin_reg.predict(X_test)),2))\n",
    "    print(\"------\")\n",
    "    print(\"Train MSE:\", round(metrics.mean_squared_error(y_train, ridgeR.predict(X_train)),2))\n",
    "    print(\"Test MSE:\", round(metrics.mean_squared_error(y_test, ridgeR.predict(X_test)),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correccion_ridge_a_aplicar(X,y,log_ini,log_fin,n_alphas,alpha_1,test_size_1,random_state_1):\n",
    "\n",
    "    lin_reg = LinearRegression() \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=random_state_1)\n",
    "    lin_reg.fit(X_train, y_train)                           #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "\n",
    "    predictions = lin_reg.predict(X_test)                   #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "    ridgeR = Ridge(alpha = alpha_1)\n",
    "    ridgeR.fit(X_train, y_train)\n",
    "\n",
    "    alphas = np.logspace(log_ini, log_fin, n_alphas) \n",
    "    baseline_error = metrics.mean_squared_error(y_test, lin_reg.predict(X_test))\n",
    "    coef_ridge = []\n",
    "    err_ridge = []\n",
    "    baseline = []\n",
    "\n",
    "    for a in alphas:\n",
    "        ridge = Ridge(alpha=a)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        \n",
    "        coef_ridge.append(ridge.coef_)\n",
    "        \n",
    "        y_pred = ridge.predict(X_test)\n",
    "        ridge_error = metrics.mean_squared_error(y_pred, y_test)\n",
    "        \n",
    "        err_ridge.append(ridge_error)\n",
    "        baseline.append(baseline_error)\n",
    "    print(min(err_ridge))\n",
    "    \n",
    "    plt.figure(figsize=(20,12))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(alphas, err_ridge, linewidth=5, color='red', label=\"Ridge regression\")\n",
    "    ax.plot(alphas, baseline, linewidth=4,linestyle='--', color='blue', label='Linear regression')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlabel('$\\lambda$', fontsize=30)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.ylabel('error', fontsize=30)\n",
    "    ax.legend(fontsize=30)\n",
    "    plt.title(r'Regression error ($\\lambda$)', fontsize=30)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tree_decission(dataframe,X_1,y_1,random_state_1):\n",
    "    '''\n",
    "    Función para esbozar un Tree_Decission\n",
    "    '''\n",
    "    X = X_1\n",
    "    y = y_1\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=random_state_1)\n",
    "    df_Tree_model = DecisionTreeRegressor(random_state=random_state_1)\n",
    "    df_Tree_model.fit(train_X, train_y)\n",
    "    val_predictions = df_Tree_model.predict(val_X)\n",
    "    val_mae = metrics.mean_absolute_error(val_predictions, val_y)\n",
    "    print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "    return df_Tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_forest(dataframe,X_1,y_1,random_state_1):\n",
    "    '''\n",
    "    Función para el calculo de un Random Forest en forma de regresión\n",
    "    '''\n",
    "    X = X_1\n",
    "    y = y_1\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_1, y_1, random_state=random_state_1)\n",
    "    forest_model = RandomForestRegressor(random_state=random_state_1)\n",
    "    forest_model.fit(train_X, train_y)\n",
    "    predictions = forest_model.predict(val_X)\n",
    "    print(mean_absolute_error(val_y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_Lasso(X,y,test_size_1,random_state_1,alpha_1):\n",
    "\n",
    "    lin_reg = LinearRegression() \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=random_state_1)\n",
    "    lin_reg.fit(X_train, y_train)                           #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "    predictions = lin_reg.predict(X_test)                   #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "\n",
    "    print(\"El factor de correlacion de la regresión es: \",lin_reg.score(X_test, y_test))\n",
    "    print(\"Errores de las predicciones\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    print(\"\\nErrores de los tests\\n---\")\n",
    "    print('MAE:', metrics.mean_absolute_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MAPE:', metrics.mean_absolute_percentage_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('MSE:', metrics.mean_squared_error(y_train, lin_reg.predict(X_train)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, lin_reg.predict(X_train))))\n",
    "\n",
    "    lassoR = Lasso(alpha=alpha_1)\n",
    "    lassoR.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train MSE sin regularización:\", round(metrics.mean_squared_error(y_train, lin_reg.predict(X_train)),2))\n",
    "    print(\"Test MSE sin regularización:\", round(metrics.mean_squared_error(y_test, lin_reg.predict(X_test)),2))\n",
    "\n",
    "    print(\"Train MSE: %0.4f\" % metrics.mean_squared_error(y_train, lassoR.predict(X_train)))\n",
    "    print(\"Test MSE: %0.4f\" % metrics.mean_squared_error(y_test, lassoR.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correccion_Lasso_a_aplicar(X,y,test_size_1,random_state_1,alpha_1,log_ini,log_fin,n_alphas):\n",
    "\n",
    "    lin_reg = LinearRegression() \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=random_state_1)\n",
    "    lin_reg.fit(X_train, y_train)                           #   Entrenas/generas el modelo para determinar los coeficientes\n",
    "    predictions = lin_reg.predict(X_test)                   #   Determino los resultados que deberían de dar con los valores guardados para\n",
    "\n",
    "    lassoR = Lasso(alpha=alpha_1)\n",
    "    lassoR.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train MSE sin regularización:\", round(metrics.mean_squared_error(y_train, lin_reg.predict(X_train)),2))\n",
    "    print(\"Test MSE sin regularización:\", round(metrics.mean_squared_error(y_test, lin_reg.predict(X_test)),2))\n",
    "\n",
    "    print(\"Train MSE: %0.4f\" % metrics.mean_squared_error(y_train, lassoR.predict(X_train)))\n",
    "    print(\"Test MSE: %0.4f\" % metrics.mean_squared_error(y_test, lassoR.predict(X_test)))\n",
    "    \n",
    "    lasso = linear_model.Lasso(fit_intercept=False)\n",
    "\n",
    "    coef_lasso = []\n",
    "    err_lasso = []\n",
    "    baseline = []\n",
    "    alphas = np.logspace(log_ini,log_fin, n_alphas)\n",
    "    for a in alphas:\n",
    "        lasso.set_params(alpha=a)\n",
    "        lasso.fit(X_train, y_train)\n",
    "        coef_lasso.append(lasso.coef_)\n",
    "        y_pred = lasso.predict(X_test)\n",
    "        lasso_error = metrics.mean_squared_error(y_pred, y_test)    \n",
    "        err_lasso.append(lasso_error)\n",
    "    print(min(err_lasso))\n",
    "#    plt.figure(figsize=(20,10))\n",
    "#    ax = plt.gca()\n",
    "#    ax.plot(alphas, err_lasso, linewidth=5, color='red', label=\"Lasso\")\n",
    "#    ax.plot(alphas, baseline, linewidth=4,linestyle='--', color='blue', label='Linear regression')\n",
    "#    ax.set_xscale('log')\n",
    "#    plt.xlabel('$\\lambda$', fontsize=30)\n",
    "#    plt.xticks(fontsize=30)\n",
    "#    plt.yticks(fontsize=30)\n",
    "#    plt.ylabel('error', fontsize=30)\n",
    "#    ax.legend(fontsize=30)\n",
    "#    plt.title(r'Regression error ($\\lambda$)', fontsize=30)\n",
    "#   plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0e4a4af33acb5d51fe8962d9e2e7588108ae49a894b6d1e35c2101e79360239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
